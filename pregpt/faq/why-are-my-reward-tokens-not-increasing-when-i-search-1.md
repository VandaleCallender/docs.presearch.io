---
description: Technical details aspects
---

# Service operation

## Who created PreGPT?

The backend is managed by Salad.com and Presearch in tandem.&#x20;

## What is used to Power PreGPT ?

PreGPT is fueled by Salad.comâ€™s decentralized network of GPU nodes. For more insights into Salad's distributed cloud technology, visit their [blog](https://blog.salad.com/ai-gpu-shortage-distributed-cloud/?utm\_source=email\&utm\_medium=pu-email\&utm\_campaign=tw-cloud) and [website](https://salad.com/).

## What is the underlying LLM model ?

PreGPT currently uses the Mistral 7B LLM model. For more details, visit [Mistral's announcement](https://mistral.ai/news/announcing-mistral-7b/).

## Is PreGPT built from open source components?

Many parts of PreGPT, including the LLMs and the UI (forked from Hugging Face), are open-sourced. The inference endpoints are hosted by Salad.com.

## What are the downtime expectations?

While we aim for consistent uptime, occasional downtime may occur due to high demand.

## What are the limitations of PreGPT ?

Like all chatbots, PreGPT has its boundaries. It does not provide real-time or web-based information and operates with knowledge up until roughly Spring 2023, when the Mistral 7B training data ended. The current LLM model primarily supports English, with limited capabilities in other languages.
